{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aef9699",
   "metadata": {},
   "source": [
    "# üß† Jupyter Notebook ‚Äì Model z konfigurace `config_20250726_174331.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f61c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    InputLayer, Conv2D, MaxPooling2D, Flatten, Dense, Dropout,\n",
    "    BatchNormalization, Activation\n",
    ")\n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0702502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfigurace modelu\n",
    "config = {\n",
    "    \"global_config\": {\n",
    "        \"name\": \"\",\n",
    "        \"optimizer\": \"adam\",\n",
    "        \"loss_function\": \"categorical_crossentropy\",\n",
    "        \"metrics\": \"accuracy\",\n",
    "        \"epochs\": 18,\n",
    "        \"batch_size\": 128,\n",
    "        \"augmentation\": \"TRUE\"\n",
    "    },\n",
    "    \"selected_dataset\": {\n",
    "        \"family\": \"MNIST\",\n",
    "        \"name\": \"fashion_mnist\"\n",
    "    },\n",
    "    \"layers\": [\n",
    "        {\n",
    "            \"type\": \"Input\",\n",
    "            \"data\": {\n",
    "                \"input_shape\": \"[28, 28, 1]\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"Conv2D\",\n",
    "            \"data\": {\n",
    "                \"filters\": 128,\n",
    "                \"kernel_size\": \"3\",\n",
    "                \"stride\": \"1\",\n",
    "                \"padding\": \"same\",\n",
    "                \"activation\": \"ReLU\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"MaxPooling2D\",\n",
    "            \"data\": {\n",
    "                \"pool_size\": \"2\",\n",
    "                \"stride\": \"1\",\n",
    "                \"padding\": \"same\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"Conv2D\",\n",
    "            \"data\": {\n",
    "                \"filters\": 128,\n",
    "                \"kernel_size\": \"3\",\n",
    "                \"stride\": \"1\",\n",
    "                \"padding\": \"same\",\n",
    "                \"activation\": \"ReLU\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"MaxPooling2D\",\n",
    "            \"data\": {\n",
    "                \"pool_size\": \"3\",\n",
    "                \"stride\": \"1\",\n",
    "                \"padding\": \"same\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"Flatten\",\n",
    "            \"data\": {\n",
    "                \"dummy\": \"flatten\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"Dense\",\n",
    "            \"data\": {\n",
    "                \"units\": 1024,\n",
    "                \"activation\": \"ReLU\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"Dropout\",\n",
    "            \"data\": {\n",
    "                \"rate\": 0.5\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"Dense\",\n",
    "            \"data\": {\n",
    "                \"units\": 10,\n",
    "                \"activation\": \"softmax\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7194eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_TYPE_MAP = {\n",
    "    \"Input\": lambda params: InputLayer(shape=tuple(params[\"input_shape\"])),\n",
    "    \"Conv2D\": lambda params: Conv2D(\n",
    "        filters=int(params[\"filters\"]),\n",
    "        kernel_size=int(params[\"kernel_size\"]),\n",
    "        activation=params.get(\"activation\", None),\n",
    "        padding=params.get(\"padding\", \"valid\")\n",
    "    ),\n",
    "    \"MaxPooling2D\": lambda params: MaxPooling2D(pool_size=int(params[\"pool_size\"])),\n",
    "    \"Flatten\": lambda params: Flatten(),\n",
    "    \"Dense\": lambda params: Dense(\n",
    "        units=int(params[\"units\"]),\n",
    "        activation=params.get(\"activation\", None)\n",
    "    ),\n",
    "    \"Dropout\": lambda params: Dropout(rate=float(params[\"rate\"])),\n",
    "    \"BatchNormalization\": lambda params: BatchNormalization(),\n",
    "    \"Activation\": lambda params: Activation(params[\"activation\"])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf781cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "for layer_cfg in config[\"layers\"]:\n",
    "    layer_type = layer_cfg[\"type\"]\n",
    "    layer_params = layer_cfg[\"data\"]\n",
    "    if \"activation\" in layer_params and isinstance(layer_params[\"activation\"], str):\n",
    "        layer_params[\"activation\"] = layer_params[\"activation\"].lower()\n",
    "    layer_fn = LAYER_TYPE_MAP.get(layer_type)\n",
    "    if not layer_fn:\n",
    "        raise ValueError(f\"Nezn√°m√Ω typ vrstvy: {layer_type}\")\n",
    "    model.add(layer_fn(layer_params))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e340c38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üèÉ‚Äç‚ôÇÔ∏è Kompilace a tr√©nink modelu\n",
    "train_cfg = config.get(\"global_config\", {})\n",
    "\n",
    "optimizer = train_cfg.get(\"optimizer\", \"adam\")\n",
    "loss = train_cfg.get(\"loss_function\", \"sparse_categorical_crossentropy\")\n",
    "metrics = [train_cfg.get(\"metrics\", \"accuracy\")]\n",
    "epochs = int(train_cfg.get(\"epochs\", 10))\n",
    "batch_size = int(train_cfg.get(\"batch_size\", 32))\n",
    "validation_split = float(train_cfg.get(\"validation_split\", 0.2)) if \"validation_split\" in train_cfg else 0.2\n",
    "\n",
    "# üéØ P≈ôevod ≈°t√≠tk≈Ø na one-hot, pokud je loss = categorical_crossentropy\n",
    "if loss == \"categorical_crossentropy\":\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    y_train = to_categorical(y_train, num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "history = model.fit(\n",
    "x_train, y_train,\n",
    "epochs=epochs,\n",
    "batch_size=batch_size,\n",
    "validation_split=validation_split\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f645f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ Vyhodnocen√≠ modelu\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"üìä Test loss: {test_loss:.4f}\")\n",
    "print(f\"‚úÖ Test accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
